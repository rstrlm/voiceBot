# voiceBot

This is a test project done mostly with Vibe Coding 
A fully local, privacy-friendly Discord voice bot that can **listen**, **understand**, **think**, and **speak** in real time.

The bot joins a Discord voice channel, listens to users, transcribes speech with Whisper, generates replies using a local LLM (Ollama), synthesizes speech with Piper TTS, and plays the response back into Discord â€” **only when a wake word is spoken** (e.g. *â€œbotâ€*, *â€œhey botâ€*).

## âœ¨ Features

* ğŸ§ Discord voice receive & playback
* ğŸ—£ï¸ Speech-to-Text using **Whisper (faster-whisper)**
* ğŸ¤– Local LLM responses via **Ollama**
* ğŸ”Š Text-to-Speech using **Piper (piper-tts / piper1-gpl)**
* ğŸ’¤ Wake-word activation (no accidental replies)
* ğŸ”’ Fully local â€” **no cloud audio processing**
* ğŸ§  Modular Node.js + Python architecture
* âš¡ Real-time interaction in voice channels

## ğŸ§© Architecture Overview

```
Discord Voice Channel
        â†“
Node.js Bot (@discordjs/voice)
        â†“ PCM Audio
FastAPI Backend (Python)
        â†“
Whisper (Speech â†’ Text)
        â†“
Ollama (LLM Response)
        â†“
Piper (Text â†’ Speech)
        â†“ WAV
Node.js Bot
        â†“
Discord Voice Playback
```

## ğŸ› ï¸ Tech Stack

### Node.js

* `discord.js`
* `@discordjs/voice`
* `@discordjs/opus`
* `prism-media`

### Python

* `fastapi`
* `uvicorn`
* `faster-whisper`
* `piper-tts`
* `numpy`
* `requests`

### AI / Audio

* **Whisper** â€” speech-to-text
* **Ollama** â€” local LLM inference
* **Piper** â€” local text-to-speech
* **FFmpeg + Opus** â€” audio handling

## ğŸ“ Project Structure

```
project/
â”‚
â”œâ”€ voiceBot/
â”‚   â”œâ”€ bot.js                # Discord voice bot (Node.js)
â”‚   â”œâ”€ processor_server.py   # STT + LLM + TTS backend (Python)
â”‚   â”œâ”€ package.json
â”‚
â”œâ”€ .gitignore
â”œâ”€ README.md
```

> Piper voice models (`*.onnx`) are stored **next to `processor_server.py`** and ignored by Git.

## ğŸš€ Setup Guide

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/rstrlm/voiceBot.git
cd voiceBot
```

### 2ï¸âƒ£ Node.js Setup

```bash
cd voiceBot
npm install
```

Create a `.env` file (recommended):

```env
DISCORD_TOKEN=your_discord_bot_token_here
```

### 3ï¸âƒ£ Python Setup

Create and activate a virtual environment:

```bash
python -m venv venv
```

**Windows**

```bash
venv\Scripts\activate
```

**Linux / macOS**

```bash
source venv/bin/activate
```

Install dependencies:

```bash
pip install fastapi uvicorn faster-whisper piper-tts numpy requests
```

### 4ï¸âƒ£ Download a Piper Voice Model

```bash
python -m piper.download_voices en_US-amy-medium
```

Place `en_US-amy-medium.onnx` **next to** `processor_server.py`.

### 5ï¸âƒ£ Start Ollama

Install Ollama:
[https://ollama.com](https://ollama.com)

Pull and run a model:

```bash
ollama pull phi3
ollama run phi3
```

Ollama must remain running in the background.

### 6ï¸âƒ£ Run the Python Backend

```bash
python processor_server.py
```

Expected output:

```
[Piper] Loading voice model: en_US-amy-medium.onnx
[Piper] Model loaded successfully.
```

### 7ï¸âƒ£ Run the Discord Bot

```bash
node bot.js
```

## ğŸ® Usage

1. Join a Discord voice channel
2. In a text channel, type:

   ```
   !join
   !listen
   ```
3. Speak using a wake word:

   * â€œhey bot what time is it?â€
   * â€œbot tell me a jokeâ€
4. The bot replies **in voice**

## ğŸ”‘ Wake Word System

Configured in `processor_server.py`:

```python
WAKE_WORDS = ["bot", "hey bot"]
```

* The bot ignores speech unless a wake word is detected
* Wake words are removed before sending text to the LLM

Example:

* â€œhey bot whatâ€™s the weatherâ€ â†’ â€œwhatâ€™s the weatherâ€

## ğŸ”’ Privacy & Local Processing

* No cloud STT / TTS
* No audio storage
* Whisper, Ollama, and Piper all run locally
* Audio is processed in memory only

## ğŸ§ª Troubleshooting

### Bot doesnâ€™t respond

* Say the wake word clearly
* Confirm Python backend is running
* Confirm Ollama is running and model is available

### No audio playback

* Ensure FFmpeg is installed/working
* Ensure `@discordjs/opus` is installed

### Piper errors

* Use CPU-friendly Piper models (low/medium often easiest)
* Confirm `.onnx` file path is correct

## ğŸ“ˆ Future Improvements

* Streaming TTS (speak while thinking)
* Multiple voices per user
* Conversation memory
* Confidence-based wake word detection
* Voice commands (â€œbot stopâ€, â€œbot go silentâ€, etc.)
* Dockerized deployment

## ğŸ“œ License

MIT (or your preferred license)

## â¤ï¸ Credits

* Discord.js
* faster-whisper (Whisper)
* Ollama
* Piper TTS (piper-tts / piper1-gpl)

---
